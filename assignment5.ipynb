{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SztfI17Qlln"
      },
      "source": [
        "# CS506 HW5: Predicting Customer Churn Using KNN\n",
        "------------------------------------------------\n",
        "Prediction of customer churn in the banking industry using the K-Nearest Neighbors (KNN) Algorithm.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "hI82RAtWRoVG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "jkDWCdC9cbth"
      },
      "outputs": [],
      "source": [
        "def standard_scaler(data):\n",
        "    \"\"\"Applies standard scaling to the input data.\"\"\"\n",
        "    mean = np.mean(data, axis=0)\n",
        "    std = np.std(data, axis=0)\n",
        "    scaled_data = (data - mean) / std\n",
        "    return scaled_data\n",
        "\n",
        "def one_hot_encoder(df, column):\n",
        "    unique_values = df[column].unique()\n",
        "    for value in unique_values:\n",
        "        df[column + '_' + str(value)] = (df[column] == value).astype(int)\n",
        "    df = df.drop(columns=[column])\n",
        "    return df\n",
        "\n",
        "def impute_missing_values(df):\n",
        "    # Imputes missing values using the mean strategy.\n",
        "    for col in df.columns:\n",
        "        if df[col].isnull().any():\n",
        "            df[col] = df[col].fillna(df[col].mean())\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "VbnWOCqISoju"
      },
      "outputs": [],
      "source": [
        "# Define the KNN Class from Scratch\n",
        "class KNN:\n",
        "    def __init__(self, k=3, distance_metric='euclidean'):\n",
        "        self.k = k\n",
        "        self.distance_metric = distance_metric\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Store training data\n",
        "        self.X_train = np.array(X)\n",
        "        self.y_train = np.array(y)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        X = np.array(X)\n",
        "        predictions = []\n",
        "\n",
        "        for x_test in X:\n",
        "            # Compute distances between x_test and all training samples one by one\n",
        "            distances = self.compute_distance(self.X_train, x_test)\n",
        "\n",
        "            # Get the indices of the k nearest neighbors\n",
        "            nearest_neighbors_indices = np.argpartition(distances, self.k)[:self.k]\n",
        "\n",
        "            # Retrieve the labels of the nearest neighbors\n",
        "            nearest_labels = self.y_train[nearest_neighbors_indices]\n",
        "\n",
        "            # Calculate the probability for the positive class\n",
        "            positive_class_prob = np.sum(nearest_labels) / self.k\n",
        "\n",
        "            # Append both class probabilities [P(negative), P(positive)]\n",
        "            predictions.append([1 - positive_class_prob, positive_class_prob])\n",
        "\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def compute_distance(self, X1, X2):\n",
        "        X1 = X1.astype(np.float64)\n",
        "        X2 = X2.astype(np.float64)\n",
        "        X2 = X2.reshape(1, -1)\n",
        "\n",
        "        if self.distance_metric == 'euclidean':\n",
        "          # Vectorized Euclidean distance\n",
        "          return np.sqrt(np.sum((X1 - X2)**2, axis=1))\n",
        "        elif self.distance_metric == 'manhattan':\n",
        "          # Vectorize Manhattan distance\n",
        "          return np.sum(np.abs(X1 - X2), axis=1)\n",
        "        else:\n",
        "          raise ValueError(\"Unsupported distance metric\")\n",
        "    \n",
        "    def predict(self, X):\n",
        "        probabilities = self.predict_proba(X)\n",
        "        return np.argmax(probabilities, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "-HnfFTTGUQ-c"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(train_path, test_path):\n",
        "    train_data = pd.read_csv(\"train.csv\")\n",
        "    test_data = pd.read_csv(\"test.csv\")\n",
        "\n",
        "    # Separate features and labels\n",
        "    X_train = train_data.drop(columns=['Exited', 'CustomerId', 'Surname'])\n",
        "    y_train = train_data['Exited'].values\n",
        "    X_test = test_data.drop(columns=['CustomerId', 'Surname'])\n",
        "\n",
        "    for col in ['Geography']:\n",
        "        X_train = one_hot_encoder(X_train, col)\n",
        "        X_test = one_hot_encoder(X_test, col)\n",
        "\n",
        "    # Encode categorical features: Gender and Geography before imputation\n",
        "    X_train['Gender'] = X_train['Gender'].map({'Male': 1, 'Female': 0})\n",
        "    X_test['Gender'] = X_test['Gender'].map({'Male': 1, 'Female': 0})\n",
        "\n",
        "    # Handle missing values for both train and test sets (impute)\n",
        "    X_train = impute_missing_values(X_train)\n",
        "    X_test = impute_missing_values(X_test)\n",
        "\n",
        "    # Select only numerical columns for scaling\n",
        "    numerical_cols = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "    # Standard scale numerical columns\n",
        "    X_train[numerical_cols] = standard_scaler(X_train[numerical_cols].values)\n",
        "    X_test[numerical_cols] = standard_scaler(X_test[numerical_cols].values)\n",
        "\n",
        "    X_train, X_test, y_train = X_train.values, X_test.values, y_train\n",
        "    \n",
        "    return X_train, X_test, y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "DwJ9n90hjGIj"
      },
      "outputs": [],
      "source": [
        "def calculate_roc_auc_manual(y_true, y_scores):\n",
        "    thresholds = np.unique(y_scores)\n",
        "    thresholds = np.sort(thresholds)[::-1]\n",
        "    tpr_list, fpr_list = [], []\n",
        "    P = np.sum(y_true == 1)\n",
        "    N = np.sum(y_true == 0)\n",
        "    for threshold in thresholds:\n",
        "        y_pred = (y_scores >= threshold).astype(int)\n",
        "        TP = np.sum((y_true == 1) & (y_pred == 1))\n",
        "        FP = np.sum((y_true == 0) & (y_pred == 1))\n",
        "        tpr_list.append(TP / P if P > 0 else 0)\n",
        "        fpr_list.append(FP / N if N > 0 else 0)\n",
        "    return np.trapz(tpr_list, fpr_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "0bmz2OYlWZGG"
      },
      "outputs": [],
      "source": [
        "def cross_validate_with_metrics(X, y, k, distance_metric, n_splits=5):\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    \n",
        "    indices = np.arange(len(X))\n",
        "    np.random.shuffle(indices)\n",
        "    X = X[indices]\n",
        "    y = y[indices]\n",
        "\n",
        "    fold_size = len(X) // n_splits\n",
        "    auc_list = []\n",
        "\n",
        "    for i in range(n_splits):\n",
        "        # Splitting data\n",
        "        X_val = X[i * fold_size: (i + 1) * fold_size]\n",
        "        y_val = y[i * fold_size: (i + 1) * fold_size]\n",
        "        X_train = np.concatenate((X[:i * fold_size], X[(i + 1) * fold_size:]), axis=0)\n",
        "        y_train = np.concatenate((y[:i * fold_size], y[(i + 1) * fold_size:]), axis=0)\n",
        "\n",
        "        # Train KNN\n",
        "        knn = KNN(k=k, distance_metric=distance_metric)\n",
        "        knn.fit(X_train, y_train)\n",
        "\n",
        "        # Predict probabilities and convert to predicted labels\n",
        "        y_pred_proba = knn.predict_proba(X_val)[:, 1]\n",
        "\n",
        "        y_pred = (y_pred_proba >= 0.5).astype(int)  # Threshold at 0.5\n",
        "\n",
        "        # Compute metrics\n",
        "        auc = calculate_roc_auc_manual(y_val, y_pred_proba)\n",
        "\n",
        "        # Append metrics to lists\n",
        "        auc_list.append(auc)\n",
        "\n",
        "    # Return average of the metrics across the folds\n",
        "    return {\n",
        "        \"auc\": np.mean(auc_list)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "zClJbYr7Ybv8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Higher AUC score for each k:\n",
            "k: 1, Distance Metric: manhattan, AUC: 0.8854\n",
            "k: 2, Distance Metric: euclidean, AUC: 0.8062\n",
            "k: 3, Distance Metric: euclidean, AUC: 0.8393\n",
            "k: 4, Distance Metric: euclidean, AUC: 0.8565\n",
            "k: 5, Distance Metric: manhattan, AUC: 0.8854\n",
            "k: 6, Distance Metric: euclidean, AUC: 0.8736\n",
            "k: 7, Distance Metric: manhattan, AUC: 0.8854\n",
            "k: 8, Distance Metric: manhattan, AUC: 0.8854\n",
            "k: 9, Distance Metric: manhattan, AUC: 0.8854\n",
            "k: 10, Distance Metric: euclidean, AUC: 0.8893\n",
            "k: 11, Distance Metric: euclidean, AUC: 0.8913\n",
            "k: 12, Distance Metric: manhattan, AUC: 0.8854\n",
            "k: 13, Distance Metric: manhattan, AUC: 0.8854\n",
            "k: 14, Distance Metric: manhattan, AUC: 0.8854\n",
            "k: 15, Distance Metric: manhattan, AUC: 0.8854\n",
            "k: 16, Distance Metric: manhattan, AUC: 0.8854\n",
            "k: 17, Distance Metric: euclidean, AUC: 0.8966\n",
            "k: 18, Distance Metric: manhattan, AUC: 0.8854\n",
            "k: 19, Distance Metric: manhattan, AUC: 0.8854\n",
            "k: 20, Distance Metric: manhattan, AUC: 0.8854\n",
            "Optimal k: 20, Distance Metric: manhattan, Best AUC: 0.9004\n",
            "Test predictions saved to 'submissions.csv'\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess data\n",
        "X, X_test, y = preprocess_data('train.csv', 'test.csv')\n",
        "\n",
        "# Hyperparameter tuning to find the best value of k\n",
        "results = []\n",
        "best_k = None\n",
        "best_distance_metric = None\n",
        "best_score = 0\n",
        "\n",
        "# Store predictions for each distance metric\n",
        "euclidean_predictions = []\n",
        "manhattan_predictions = []\n",
        "\n",
        "# Iterate over k values from 1 to 20\n",
        "for k in range(1, 21):  \n",
        "    # Calculate AUC for Euclidean distance\n",
        "    auc_euclidean = cross_validate_with_metrics(X, y, k, 'euclidean')[\"auc\"]\n",
        "\n",
        "    # Calculate AUC for Manhattan distance\n",
        "    auc_manhattan = cross_validate_with_metrics(X, y, k, 'manhattan')[\"auc\"]\n",
        "\n",
        "    # Initialize KNN model for Euclidean distance and fit it\n",
        "    knn_euclidean = KNN(k=k, distance_metric='euclidean')\n",
        "    knn_euclidean.fit(X, y)\n",
        "    # Predict probabilities for the Exited class (1) for test data\n",
        "    euclidean_pred = knn_euclidean.predict_proba(X_test)[:, 1]  \n",
        "\n",
        "    # Initialize KNN model for Manhattan distance and fit it\n",
        "    knn_manhattan = KNN(k=k, distance_metric='manhattan')\n",
        "    knn_manhattan.fit(X, y)\n",
        "    manhattan_pred = knn_manhattan.predict_proba(X_test)[:, 1]  \n",
        "\n",
        "    # Store predictions\n",
        "    euclidean_predictions.append(euclidean_pred)\n",
        "    manhattan_predictions.append(manhattan_pred)\n",
        "\n",
        "    # Compare and store the better AUC score for each k\n",
        "    if auc_euclidean > auc_manhattan:\n",
        "        results.append((k, 'euclidean', auc_euclidean))\n",
        "    else:\n",
        "        results.append((k, 'manhattan', auc_manhattan))\n",
        "\n",
        "    # Update the best AUC score\n",
        "    if auc_manhattan > best_score:\n",
        "        best_score = auc_manhattan\n",
        "        best_k = k\n",
        "        best_distance_metric = 'manhattan'\n",
        "    if auc_euclidean > best_score:\n",
        "        best_score = auc_euclidean\n",
        "        best_k = k\n",
        "        best_distance_metric = 'euclidean'\n",
        "\n",
        "# Print the results with the higher AUC score for each k\n",
        "print(\"Higher AUC score for each k:\")\n",
        "for result in results:\n",
        "    print(f'k: {result[0]}, Distance Metric: {result[1]}, AUC: {result[2]:.4f}')\n",
        "\n",
        "print(f'Optimal k: {best_k}, Distance Metric: {best_distance_metric}, Best AUC: {best_score:.4f}')\n",
        "\n",
        "# Now generate the final predictions by choosing the higher probability for each test example\n",
        "final_predictions = np.maximum(euclidean_predictions[best_k-1], manhattan_predictions[best_k-1])\n",
        "\n",
        "# Create and save the submission file in the correct format\n",
        "test_data = pd.read_csv('test.csv')  # Load original test file for CustomerId\n",
        "submission = pd.DataFrame({'id': test_data['id'], 'Exited': final_predictions})\n",
        "submission.to_csv('submissions.csv', index=False)\n",
        "\n",
        "print(\"Test predictions saved to 'submissions.csv'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLO6NfLIa4lX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
